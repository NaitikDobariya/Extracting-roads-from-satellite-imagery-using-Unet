# Extracting-roads-from-satellite-imagery-using-Unet

### Road Extraction using U-Net

This repository houses an attempt to implement a U-Net architecture for the extraction of roads, alleys, and pathways from satellite images. The project primarily revolves around a Kaggle Jupyter notebook for training the model.

#### About the Project

The primary objective of this project is to utilize a U-Net architecture for semantic segmentation tasks, particularly in extracting road networks from satellite imagery. The project addresses challenges associated with urban planning, transportation management, and environmental monitoring.

[Link to Kaggle Notebook](https://www.kaggle.com/code/dobariyanaitik/road-extraction-using-u-net)

#### Libraries Used

- pandas
- PIL (Python Imaging Library)
- cv2 (OpenCV)
- tqdm (progress bars)
- matplotlib
- numpy
- tensorflow
- keras

#### Results

The mode achieved rapid convergence and minimal training loss, this could also indicate that the model is unable to learn further. Below is the training curve illustrating the model's performance:

![__results___9_0](https://github.com/NaitikDobariya/Extracting-roads-from-satellite-imagery-using-Unet/assets/113834773/cc42673d-0586-45b0-8ae9-95de37332f42)


However, it is essential to note that the segmentation results generated by the U-Net model do not meet desired expectations. Several factors contribute to this discrepancy, including suboptimal model architecture, utilization of highly compressed images, and potential variations in data quality.

Examples of segmentation results are presented below:

Segmentation Result 

![__results___12_1](https://github.com/NaitikDobariya/Extracting-roads-from-satellite-imagery-using-Unet/assets/113834773/0a0f770a-f838-4ab2-96fc-4bbd55ac08f9)


While efforts have been made to optimize the model and its training parameters, it is imperative to acknowledge the inherent limitations and challenges associated with such tasks. Further refinement and experimentation may be necessary to improve the model's performance.

Thank you for your interest and understanding, changes and suggestions are welcome.
